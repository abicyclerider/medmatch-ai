# MedMatch AI

An AI-powered medical entity resolution system that prevents wrong-patient errors in healthcare using AI (Google Gemini API or local MedGemma via Ollama).

## Problem Statement

Wrong-patient medical errors (e.g., operating on the wrong John Smith) are "never events" that cause deaths. Current systems use basic name matching. MedMatch AI uses deep medical understanding to create "medical fingerprints" ensuring accurate patient matching at critical decision points.

## Approach

Instead of simple demographic matching, we use a hybrid 4-stage pipeline:

1. **Blocking** - Reduces O(n¬≤) comparisons by 97% using phonetic and key-based strategies
2. **Deterministic Rules** - Fast exact matching for clear cases (74% of decisions)
3. **Feature Scoring** - Weighted confidence scores for moderate difficulty cases
4. **AI Medical Fingerprinting** - Deep medical history comparison using Gemini API or local MedGemma

The system understands:

- Medical abbreviations (T2DM = Type 2 Diabetes, HTN = Hypertension)
- Name variations and typos (Jennifer vs Jenny, Johnson vs Jonson)
- Date format differences and errors (03/15/1980 vs 3/15/80)
- Medical context (Metformin ‚Üí Diabetes treatment)
- Clinical narratives and medication histories

## Project Status

‚úÖ **Phase 1 Complete** - Synthetic data generation system
‚úÖ **Phase 2 Complete** - AI-powered entity resolution (94.51% accuracy)
‚úÖ **Phase 4 Complete** - Local MedGemma deployment via Ollama
üöÄ **Phase 5 Starting** - Production service architecture (PostgreSQL + REST API + Docker)

### Current Capabilities

- **94.51% overall accuracy** on patient matching across all difficulty levels
- **4-stage progressive pipeline**: Blocking ‚Üí Rules ‚Üí Scoring ‚Üí AI Medical Fingerprinting
- **97% efficiency improvement** through intelligent blocking (33,930 ‚Üí 437 pairs)
- **100% accuracy on AI decisions** for medical history comparison
- **Explainable decisions** with confidence scores and human-readable explanations
- **HIPAA-compliant** local inference via Ollama + MedGemma

## Entity Resolution Results

Our 4-stage progressive pipeline achieves exceptional accuracy on synthetic patient matching:

**Overall Performance (437 test pairs):**

- **Accuracy:** 94.51%
- **Precision:** 95%
- **Recall:** 96%
- **F1 Score:** 95%

**Accuracy by Difficulty:**

| Difficulty | Target | Achieved | Status |
| ---------- | ------ | -------- | ------ |
| Easy | 95% | **100.00%** | ‚úÖ PASS |
| Medium | 85% | **100.00%** | ‚úÖ PASS |
| Hard | 70% | **88.24%** | ‚úÖ PASS |
| Ambiguous | 70% | **80.54%** | ‚úÖ PASS |

**Pipeline Stages:**

1. **Blocking:** Reduces candidate pairs by 97% (33,930 ‚Üí ~1,000) with 97.3% recall
2. **Deterministic Rules:** Handles 74% of decisions with 92.6% accuracy
3. **Feature Scoring:** Handles 0% of decisions (when AI enabled, otherwise 26% with 87.6% accuracy)
4. **AI Medical Fingerprinting:** Handles 26% of decisions with 100% accuracy

All targets exceeded! See [evaluation notebook](notebooks/01_entity_resolution_evaluation.ipynb) for detailed analysis.

## Tech Stack

- **Python 3.12.4** with venv
- **PyTorch 2.9.1** (Mac Metal/MPS acceleration)
- **AI Backends:**
  - **Ollama + MedGemma 1.5 4B** (local inference, HIPAA-compliant)
  - **Google Gemini API** (development/testing)
- **Data Processing:** pandas, numpy, pydicom
- **Development:** Jupyter Lab, pytest, black, ruff

## Setup

### 1. Clone and Create Virtual Environment
```bash
git clone git@github.com:abicyclerider/medmatch-ai.git
cd medmatch-ai
python3 -m venv venv
source venv/bin/activate
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Configure AI Backend

**Option A: Ollama (Recommended for Production)**

For HIPAA-compliant local inference:

```bash
# Install Ollama
brew install ollama

# Start Ollama service
brew services start ollama

# Download and import MedGemma (see docs/ollama_setup.md for details)
# Requires HuggingFace token with access to google/medgemma-1.5-4b-it
```

See [docs/ollama_setup.md](docs/ollama_setup.md) for complete setup instructions.

**Option B: Gemini API (Development/Testing)**

```bash
cp .env.example .env
# Edit .env and add your Google AI API key from https://aistudio.google.com/apikey
```

‚ö†Ô∏è **Privacy Warning**: Gemini API sends data to Google's servers. Only use with synthetic/anonymized data. For production with real patient data, use Ollama.

### 4. Verify Installation
```bash
python verify_install.py
python test_medgemma.py
```

### 5. Launch Jupyter Lab
```bash
jupyter lab
# Open notebooks/00_environment_test.ipynb
```

## Usage Examples

### Generate Synthetic Data

```bash
# Fast generation (30 seconds, rule-based)
python generate_synthetic_data.py --no-ai

# AI-assisted generation (15-20 minutes with rate limiting)
python generate_synthetic_data.py --api-rate-limit 5
```

### Run Entity Resolution (Python API)

```python
from medmatch.matching import PatientMatcher, PatientRecord
from medmatch.data.models.patient import Demographics
from datetime import date

# Load or create patient records
records = [...]  # Load from CSV or create manually

# Create matcher with Ollama (local MedGemma)
matcher = PatientMatcher(
    use_blocking=True,
    use_rules=True,
    use_scoring=True,
    use_ai=True,
    ai_backend="ollama",  # Local inference (HIPAA-compliant)
)

# Or use Gemini API (development/testing only)
matcher = PatientMatcher(
    use_blocking=True,
    use_rules=True,
    use_scoring=True,
    use_ai=True,
    ai_backend="gemini",  # Requires GOOGLE_AI_API_KEY in .env
)

# Match two specific records
result = matcher.match_pair(records[0], records[1])
print(f"Match: {result.is_match}")
print(f"Confidence: {result.confidence:.2f}")
print(f"Stage: {result.stage}")
print(result.explanation)

# Batch matching on entire dataset
results = matcher.match_datasets(records, show_progress=True)
stats = matcher.get_stats(results)
print(f"Found {stats['matches']} matches in {stats['total_pairs']} pairs")
```

### Batch Matching (CLI)

```bash
# With Ollama (local MedGemma)
python scripts/run_matcher.py \
  --demographics data/synthetic/synthetic_demographics.csv \
  --medical-records data/synthetic/synthetic_medical_records.json \
  --output results.json \
  --use-ai \
  --ai-backend ollama \
  --progress

# Or with Gemini API (development/testing)
python scripts/run_matcher.py \
  --demographics data/synthetic/synthetic_demographics.csv \
  --medical-records data/synthetic/synthetic_medical_records.json \
  --output results.json \
  --use-ai \
  --ai-backend gemini \
  --progress
```

### Evaluate Results

```python
from medmatch.evaluation import MatchEvaluator

# Evaluate against ground truth
evaluator = MatchEvaluator('data/synthetic/ground_truth.csv')
metrics = evaluator.evaluate(results)

print(f"Accuracy: {metrics.accuracy:.2%}")
print(f"Precision: {metrics.precision:.2%}")
print(f"Recall: {metrics.recall:.2%}")

# Detailed analysis in Jupyter notebook
# See notebooks/01_entity_resolution_evaluation.ipynb
```

## Project Structure

```
medmatch-ai/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ medmatch/              # Core library (pip install medmatch)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ matching/          # Entity resolution algorithms
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/              # Data models and generators
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluation/        # Metrics and evaluation tools
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ medmatch_server/       # Server package (pip install medmatch-server) [Phase 5]
‚îÇ       ‚îú‚îÄ‚îÄ persistence/       # Database layer (PostgreSQL)
‚îÇ       ‚îú‚îÄ‚îÄ service/           # Business logic layer
‚îÇ       ‚îî‚îÄ‚îÄ api/               # REST + WebSocket API
‚îÇ
‚îú‚îÄ‚îÄ docker/                    # Docker deployment [Phase 5]
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îî‚îÄ‚îÄ nginx/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                 # Jupyter notebooks for exploration
‚îú‚îÄ‚îÄ tests/                     # Test suite
‚îú‚îÄ‚îÄ scripts/                   # CLI tools and utilities
‚îú‚îÄ‚îÄ data/                      # Local data (gitignored)
‚îî‚îÄ‚îÄ docs/                      # Documentation
```

### Two-Package Architecture (Phase 5)

MedMatch is structured as a monorepo with two installable packages:

1. **`medmatch`** - Core matching library (no database dependencies)
   - For projects that only need the matching algorithms
   - `pip install medmatch`

2. **`medmatch-server`** - Full production service
   - PostgreSQL backend, REST API, WebSocket support
   - `pip install medmatch-server` or `docker-compose up`

## Development Workflow

1. **Prototype in notebooks** - Experiment with matching strategies
2. **Refactor to src/** - Move working code to package
3. **Write tests** - Ensure correctness
4. **Document** - Keep README and docs updated

## Roadmap

### Phase 1: Synthetic Data Generation ‚úÖ COMPLETE

- ‚úÖ Pydantic models for patient records
- ‚úÖ Demographics generator with variations and edge cases
- ‚úÖ AI-assisted medical record generation
- ‚úÖ Ground truth labels for evaluation
- ‚úÖ 261 records with 437 match pairs for testing

### Phase 2: Entity Resolution Algorithm ‚úÖ COMPLETE

- ‚úÖ **Phase 2.1:** Core infrastructure (PatientRecord, comparators)
- ‚úÖ **Phase 2.2:** Blocking & deterministic rules
- ‚úÖ **Phase 2.3:** Feature-based confidence scoring
- ‚úÖ **Phase 2.4:** AI medical fingerprinting (Gemini API)
- ‚úÖ **Phase 2.5:** Evaluation & explanation system
- ‚úÖ **Phase 2.6:** Documentation & polish

### Phase 4: Local MedGemma Deployment ‚úÖ COMPLETE

- ‚úÖ Ollama integration for local inference
- ‚úÖ MedGemma 1.5 4B model support (full + quantized)
- ‚úÖ 2.7x speedup via batched inference
- ‚úÖ HIPAA-compliant (all data stays local)
- ‚úÖ OllamaClient with factory pattern

### Phase 5: Production Service Architecture üöÄ IN PROGRESS

Transform MedMatch into a self-contained production service:

- [ ] **Persistence Layer** - SQLAlchemy models, repository pattern, Alembic migrations
- [ ] **Service Layer** - MatchingService, GoldenRecordService, ReviewService, BatchService
- [ ] **API Layer** - FastAPI REST + WebSocket, authentication, OpenAPI docs
- [ ] **Docker Deployment** - docker-compose with PostgreSQL, Ollama, medmatch-server

See [docs/architecture.md](docs/architecture.md) for detailed design.

### Phase 6: Advanced Features (Future)

- [ ] Uncertainty quantification for borderline cases
- [ ] Multi-modal support (imaging, lab data)
- [ ] Active learning for difficult cases
- [ ] Ensemble methods combining multiple AI models

## Documentation

- **[Architecture Guide](docs/architecture.md)** - Service architecture, database schema, API design (Phase 5)
- **[Matching Module README](src/medmatch/matching/README.md)** - Entity resolution algorithms and usage
- **[Ollama Setup Guide](docs/ollama_setup.md)** - Local MedGemma deployment instructions
- **[Quick Start Guide](docs/quickstart.md)** - 5-minute getting started guide
- **[Evaluation Notebook](notebooks/01_entity_resolution_evaluation.ipynb)** - Performance analysis with visualizations
- **[Project Context](.claude/CLAUDE.md)** - Development history and design decisions
- **[Synthetic Data Plan](docs/synthetic_data_plan.md)** - Dataset specification and generation details

## Important Notes

### Medical Data Privacy
- **Development:** Use synthetic or anonymized data only
- **API Usage:** Be cautious - data sent to Google AI
- **Production:** Must use local deployment for real patient data (HIPAA)

### Current Limitations
- Using Gemini (general model) not MedGemma (medical specialist)
- API has rate limits (free tier)
- Not yet validated for clinical use

## License

[Add your license]

## Contributors

- Alex (Developer)
- Claude Sonnet 4.5 (AI Assistant)

---

**Built for the MedGemma Challenge - Preventing wrong-patient medical errors through AI**
